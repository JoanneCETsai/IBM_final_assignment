{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib\n",
    "import matplotlib.pyplot as plt\n",
    "import urllib3\n",
    "from sklearn.utils import shuffle\n",
    "%matplotlib inline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>0</th>\n",
       "      <th>1</th>\n",
       "      <th>2</th>\n",
       "      <th>3</th>\n",
       "      <th>4</th>\n",
       "      <th>5</th>\n",
       "      <th>6</th>\n",
       "      <th>7</th>\n",
       "      <th>8</th>\n",
       "      <th>9</th>\n",
       "      <th>10</th>\n",
       "      <th>11</th>\n",
       "      <th>12</th>\n",
       "      <th>13</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>1</td>\n",
       "      <td>14.23</td>\n",
       "      <td>1.71</td>\n",
       "      <td>2.43</td>\n",
       "      <td>15.6</td>\n",
       "      <td>127</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.06</td>\n",
       "      <td>0.28</td>\n",
       "      <td>2.29</td>\n",
       "      <td>5.64</td>\n",
       "      <td>1.04</td>\n",
       "      <td>3.92</td>\n",
       "      <td>1065</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>1</td>\n",
       "      <td>13.20</td>\n",
       "      <td>1.78</td>\n",
       "      <td>2.14</td>\n",
       "      <td>11.2</td>\n",
       "      <td>100</td>\n",
       "      <td>2.65</td>\n",
       "      <td>2.76</td>\n",
       "      <td>0.26</td>\n",
       "      <td>1.28</td>\n",
       "      <td>4.38</td>\n",
       "      <td>1.05</td>\n",
       "      <td>3.40</td>\n",
       "      <td>1050</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>1</td>\n",
       "      <td>13.16</td>\n",
       "      <td>2.36</td>\n",
       "      <td>2.67</td>\n",
       "      <td>18.6</td>\n",
       "      <td>101</td>\n",
       "      <td>2.80</td>\n",
       "      <td>3.24</td>\n",
       "      <td>0.30</td>\n",
       "      <td>2.81</td>\n",
       "      <td>5.68</td>\n",
       "      <td>1.03</td>\n",
       "      <td>3.17</td>\n",
       "      <td>1185</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>1</td>\n",
       "      <td>14.37</td>\n",
       "      <td>1.95</td>\n",
       "      <td>2.50</td>\n",
       "      <td>16.8</td>\n",
       "      <td>113</td>\n",
       "      <td>3.85</td>\n",
       "      <td>3.49</td>\n",
       "      <td>0.24</td>\n",
       "      <td>2.18</td>\n",
       "      <td>7.80</td>\n",
       "      <td>0.86</td>\n",
       "      <td>3.45</td>\n",
       "      <td>1480</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>1</td>\n",
       "      <td>13.24</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.87</td>\n",
       "      <td>21.0</td>\n",
       "      <td>118</td>\n",
       "      <td>2.80</td>\n",
       "      <td>2.69</td>\n",
       "      <td>0.39</td>\n",
       "      <td>1.82</td>\n",
       "      <td>4.32</td>\n",
       "      <td>1.04</td>\n",
       "      <td>2.93</td>\n",
       "      <td>735</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>173</th>\n",
       "      <td>3</td>\n",
       "      <td>13.71</td>\n",
       "      <td>5.65</td>\n",
       "      <td>2.45</td>\n",
       "      <td>20.5</td>\n",
       "      <td>95</td>\n",
       "      <td>1.68</td>\n",
       "      <td>0.61</td>\n",
       "      <td>0.52</td>\n",
       "      <td>1.06</td>\n",
       "      <td>7.70</td>\n",
       "      <td>0.64</td>\n",
       "      <td>1.74</td>\n",
       "      <td>740</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>174</th>\n",
       "      <td>3</td>\n",
       "      <td>13.40</td>\n",
       "      <td>3.91</td>\n",
       "      <td>2.48</td>\n",
       "      <td>23.0</td>\n",
       "      <td>102</td>\n",
       "      <td>1.80</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.41</td>\n",
       "      <td>7.30</td>\n",
       "      <td>0.70</td>\n",
       "      <td>1.56</td>\n",
       "      <td>750</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>175</th>\n",
       "      <td>3</td>\n",
       "      <td>13.27</td>\n",
       "      <td>4.28</td>\n",
       "      <td>2.26</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.59</td>\n",
       "      <td>0.69</td>\n",
       "      <td>0.43</td>\n",
       "      <td>1.35</td>\n",
       "      <td>10.20</td>\n",
       "      <td>0.59</td>\n",
       "      <td>1.56</td>\n",
       "      <td>835</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>176</th>\n",
       "      <td>3</td>\n",
       "      <td>13.17</td>\n",
       "      <td>2.59</td>\n",
       "      <td>2.37</td>\n",
       "      <td>20.0</td>\n",
       "      <td>120</td>\n",
       "      <td>1.65</td>\n",
       "      <td>0.68</td>\n",
       "      <td>0.53</td>\n",
       "      <td>1.46</td>\n",
       "      <td>9.30</td>\n",
       "      <td>0.60</td>\n",
       "      <td>1.62</td>\n",
       "      <td>840</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>177</th>\n",
       "      <td>3</td>\n",
       "      <td>14.13</td>\n",
       "      <td>4.10</td>\n",
       "      <td>2.74</td>\n",
       "      <td>24.5</td>\n",
       "      <td>96</td>\n",
       "      <td>2.05</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.35</td>\n",
       "      <td>9.20</td>\n",
       "      <td>0.61</td>\n",
       "      <td>1.60</td>\n",
       "      <td>560</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>178 rows × 14 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "     0      1     2     3     4    5     6     7     8     9      10    11  \\\n",
       "0     1  14.23  1.71  2.43  15.6  127  2.80  3.06  0.28  2.29   5.64  1.04   \n",
       "1     1  13.20  1.78  2.14  11.2  100  2.65  2.76  0.26  1.28   4.38  1.05   \n",
       "2     1  13.16  2.36  2.67  18.6  101  2.80  3.24  0.30  2.81   5.68  1.03   \n",
       "3     1  14.37  1.95  2.50  16.8  113  3.85  3.49  0.24  2.18   7.80  0.86   \n",
       "4     1  13.24  2.59  2.87  21.0  118  2.80  2.69  0.39  1.82   4.32  1.04   \n",
       "..   ..    ...   ...   ...   ...  ...   ...   ...   ...   ...    ...   ...   \n",
       "173   3  13.71  5.65  2.45  20.5   95  1.68  0.61  0.52  1.06   7.70  0.64   \n",
       "174   3  13.40  3.91  2.48  23.0  102  1.80  0.75  0.43  1.41   7.30  0.70   \n",
       "175   3  13.27  4.28  2.26  20.0  120  1.59  0.69  0.43  1.35  10.20  0.59   \n",
       "176   3  13.17  2.59  2.37  20.0  120  1.65  0.68  0.53  1.46   9.30  0.60   \n",
       "177   3  14.13  4.10  2.74  24.5   96  2.05  0.76  0.56  1.35   9.20  0.61   \n",
       "\n",
       "       12    13  \n",
       "0    3.92  1065  \n",
       "1    3.40  1050  \n",
       "2    3.17  1185  \n",
       "3    3.45  1480  \n",
       "4    2.93   735  \n",
       "..    ...   ...  \n",
       "173  1.74   740  \n",
       "174  1.56   750  \n",
       "175  1.56   835  \n",
       "176  1.62   840  \n",
       "177  1.60   560  \n",
       "\n",
       "[178 rows x 14 columns]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df=pd.read_csv('/Users/chiaentsai/Library/Containers/com.microsoft.Excel/Data/Desktop/wine.csv',header=None)\n",
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data=df.groupby(0).sample(n=18)\n",
    "train_data=df.drop(test_data.index)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "test_data.to_csv('wine_test.csv',index=False,header=False)\n",
    "train_data.to_csv('wine_train.csv',index=False,header=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_data=shuffle(train_data)\n",
    "X_train=train_data.drop([0],axis=1)\n",
    "Y_train=train_data[[0]]\n",
    "X_test=test_data.drop([0],axis=1)\n",
    "Y_test=test_data[[0]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\nfrom sklearn.naive_bayes import GaussianNB\\nmodel=GaussianNB()\\n'"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "model=GaussianNB()\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"\\nmodel.fit(X_train,Y_train.values.flatten())\\nprint('The score of the model:',model.score(X_test,Y_test.values.flatten()))\\n\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "model.fit(X_train,Y_train.values.flatten())\n",
    "print('The score of the model:',model.score(X_test,Y_test.values.flatten()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "import warnings\n",
    "\n",
    "from abc import ABCMeta, abstractmethod\n",
    "\n",
    "\n",
    "import numpy as np\n",
    "from scipy.special import logsumexp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "class GaussianNB():\n",
    "    \n",
    "\n",
    " \n",
    "    def __init__(self, *, priors=None, var_smoothing=1e-9):\n",
    "        self.priors = priors\n",
    "        self.var_smoothing = var_smoothing\n",
    "\n",
    "    def fit(self, X, y, sample_weight=None):\n",
    "        \n",
    "        return self._partial_fit(X, y, np.unique(y), _refit=True,\n",
    "                                 sample_weight=sample_weight)\n",
    "\n",
    "    def _check_X(self, X):\n",
    "        return check_array(X)\n",
    "\n",
    "  \n",
    "    def _update_mean_variance(n_past, mu, var, X, sample_weight=None):\n",
    "       \n",
    "        if X.shape[0] == 0:\n",
    "            return mu, var\n",
    "\n",
    "        # Compute (potentially weighted) mean and variance of new datapoints\n",
    "        if sample_weight is not None:\n",
    "            n_new = float(sample_weight.sum())\n",
    "            new_mu = np.average(X, axis=0, weights=sample_weight)\n",
    "            new_var = np.average((X - new_mu) ** 2, axis=0,\n",
    "                                 weights=sample_weight)\n",
    "        else:\n",
    "            n_new = X.shape[0]\n",
    "            new_var = np.var(X, axis=0)\n",
    "            new_mu = np.mean(X, axis=0)\n",
    "\n",
    "        if n_past == 0:\n",
    "            return new_mu, new_var\n",
    "\n",
    "        n_total = float(n_past + n_new)\n",
    "\n",
    "        total_mu = (n_new * new_mu + n_past * mu) / n_total\n",
    "\n",
    "        old_ssd = n_past * var\n",
    "        new_ssd = n_new * new_var\n",
    "        total_ssd = (old_ssd + new_ssd +\n",
    "                     (n_new * n_past / n_total) * (mu - new_mu) ** 2)\n",
    "        total_var = total_ssd / n_total\n",
    "\n",
    "        return total_mu, total_var\n",
    "\n",
    "    def partial_fit(self, X, y, classes=None, sample_weight=None):\n",
    "        \n",
    "        return self._partial_fit(X, y, classes, _refit=False,\n",
    "                                 sample_weight=sample_weight)\n",
    "\n",
    "    def _partial_fit(self, X, y, classes=None, _refit=False,\n",
    "                     sample_weight=None):\n",
    "       \n",
    "        X, y = check_X_y(X, y)\n",
    "        if sample_weight is not None:\n",
    "            sample_weight = _check_sample_weight(sample_weight, X)\n",
    "\n",
    "        self.epsilon_ = self.var_smoothing * np.var(X, axis=0).max()\n",
    "\n",
    "        if _refit:\n",
    "            self.classes_ = None\n",
    "\n",
    "        if _check_partial_fit_first_call(self, classes):\n",
    "           \n",
    "            n_features = X.shape[1]\n",
    "            n_classes = len(self.classes_)\n",
    "            self.theta_ = np.zeros((n_classes, n_features))\n",
    "            self.sigma_ = np.zeros((n_classes, n_features))\n",
    "\n",
    "            self.class_count_ = np.zeros(n_classes, dtype=np.float64)\n",
    "\n",
    "            if self.priors is not None:\n",
    "                priors = np.asarray(self.priors)\n",
    "                # Check that the provide prior match the number of classes\n",
    "                if len(priors) != n_classes:\n",
    "                    raise ValueError('Number of priors must match number of'\n",
    "                                     ' classes.')\n",
    "                # Check that the sum is 1\n",
    "                if not np.isclose(priors.sum(), 1.0):\n",
    "                    raise ValueError('The sum of the priors should be 1.')\n",
    "                # Check that the prior are non-negative\n",
    "                if (priors < 0).any():\n",
    "                    raise ValueError('Priors must be non-negative.')\n",
    "                self.class_prior_ = priors\n",
    "            else:\n",
    "                # Initialize the priors to zeros for each class\n",
    "                self.class_prior_ = np.zeros(len(self.classes_),\n",
    "                                             dtype=np.float64)\n",
    "        else:\n",
    "            if X.shape[1] != self.theta_.shape[1]:\n",
    "                msg = \"Number of features %d does not match previous data %d.\"\n",
    "                raise ValueError(msg % (X.shape[1], self.theta_.shape[1]))\n",
    "            # Put epsilon back in each time\n",
    "            self.sigma_[:, :] -= self.epsilon_\n",
    "\n",
    "        classes = self.classes_\n",
    "\n",
    "        unique_y = np.unique(y)\n",
    "        unique_y_in_classes = np.in1d(unique_y, classes)\n",
    "\n",
    "        if not np.all(unique_y_in_classes):\n",
    "            raise ValueError(\"The target label(s) %s in y do not exist in the \"\n",
    "                             \"initial classes %s\" %\n",
    "                             (unique_y[~unique_y_in_classes], classes))\n",
    "\n",
    "        for y_i in unique_y:\n",
    "            i = classes.searchsorted(y_i)\n",
    "            X_i = X[y == y_i, :]\n",
    "\n",
    "            if sample_weight is not None:\n",
    "                sw_i = sample_weight[y == y_i]\n",
    "                N_i = sw_i.sum()\n",
    "            else:\n",
    "                sw_i = None\n",
    "                N_i = X_i.shape[0]\n",
    "\n",
    "            new_theta, new_sigma = self._update_mean_variance(\n",
    "                self.class_count_[i], self.theta_[i, :], self.sigma_[i, :],\n",
    "                X_i, sw_i)\n",
    "\n",
    "            self.theta_[i, :] = new_theta\n",
    "            self.sigma_[i, :] = new_sigma\n",
    "            self.class_count_[i] += N_i\n",
    "\n",
    "        self.sigma_[:, :] += self.epsilon_\n",
    "\n",
    "        # Update if only no priors is provided\n",
    "        if self.priors is None:\n",
    "            # Empirical prior, with sample_weight taken into account\n",
    "            self.class_prior_ = self.class_count_ / self.class_count_.sum()\n",
    "\n",
    "        return self\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'check_X_y' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-18-1f294f0895de>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mGaussianNB\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 2\u001b[0;31m \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_train\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      3\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'The score of the model:'\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mscore\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX_test\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0mY_test\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mflatten\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1a05731b888d>\u001b[0m in \u001b[0;36mfit\u001b[0;34m(self, X, y, sample_weight)\u001b[0m\n\u001b[1;32m      9\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mfit\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         return self._partial_fit(X, y, np.unique(y), _refit=True,\n\u001b[0m\u001b[1;32m     12\u001b[0m                                  sample_weight=sample_weight)\n\u001b[1;32m     13\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m<ipython-input-17-1a05731b888d>\u001b[0m in \u001b[0;36m_partial_fit\u001b[0;34m(self, X, y, classes, _refit, sample_weight)\u001b[0m\n\u001b[1;32m     55\u001b[0m                      sample_weight=None):\n\u001b[1;32m     56\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 57\u001b[0;31m         \u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcheck_X_y\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mX\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     58\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0msample_weight\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     59\u001b[0m             \u001b[0msample_weight\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0m_check_sample_weight\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mX\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'check_X_y' is not defined"
     ]
    }
   ],
   "source": [
    "model=GaussianNB()\n",
    "model.fit(X_train,Y_train.values.flatten())\n",
    "print('The score of the model:',model.score(X_test,Y_test.values.flatten()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "from sklearn.preprocessing import StandardScaler\n",
    "\n",
    "sc = StandardScaler()\n",
    "X_train_std = sc.fit_transform(X_train)\n",
    "X_test_std = sc.fit_transform(X_test)\n",
    "\n",
    "cov_mat = np.cov(X_train_std.T)  #求共變異係數矩陣\n",
    "\n",
    "eigen_vals, eigen_vecs = np.linalg.eig(cov_mat)  #求共變異係數矩陣的特徵向量及特徵值\n",
    "\n",
    "tot = sum(eigen_vals)  #計算解釋變異數比率 各特徵值/特徵值總和\n",
    "var_exp = [(i / tot) for i in sorted(eigen_vals, reverse = True)]\n",
    "cum_var_exp = np.cumsum(var_exp)\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "eigen_pairs =[(np.abs(eigen_vals[i]),eigen_vecs[:,i]) for i in range(len(eigen_vals))]\n",
    "eigen_pairs.sort(reverse=True)\n",
    "\n",
    "first = eigen_pairs[0][1]\n",
    "second = eigen_pairs[1][1]\n",
    "first = first[:,np.newaxis]\n",
    "second = second[:,np.newaxis]\n",
    "w = np.hstack((first,second))\n",
    "\n",
    "#畫散點圖\n",
    "X_train_pca = X_train_std.dot(w)\n",
    "colors = ['r', 'y', 'g']\n",
    "markers = ['s', 'x', 'o']\n",
    "for l, c, m in zip(np.unique(Y_train), colors, markers):\n",
    "    plt.scatter(X_train_pca[(Y_train.values==l).flatten(), 0], X_train_pca[(Y_train.values==l).reshape(-1), 1], c=c, label=l, marker=m) # 散點圖\n",
    "\n",
    "plt.xlabel('PC 1')\n",
    "plt.ylabel('PC 2')\n",
    "plt.legend(loc='lower right')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([2, 2, 3, 1, 2, 2, 2, 1, 3, 2, 2, 1, 2, 2, 1, 3, 3, 1, 3, 2, 2, 3,\n",
       "       1, 3, 2, 2, 1, 2, 1, 1, 3, 2, 2, 2, 2, 1, 2, 2, 1, 1, 1, 2, 2, 2,\n",
       "       2, 1, 1, 2, 2, 3, 2, 1, 1, 2, 1, 3, 1, 2, 1, 1, 2, 2, 1, 3, 1, 2,\n",
       "       1, 1, 2, 3, 3, 3, 1, 2, 3, 1, 1, 3, 3, 2, 1, 1, 3, 3, 3, 2, 2, 1,\n",
       "       2, 2, 1, 2, 3, 1, 2, 3, 1, 2, 3, 2, 3, 2, 1, 3, 3, 2, 1, 2, 3, 3,\n",
       "       1, 3, 1, 1, 3, 2, 2, 2, 1, 2, 1, 2, 2, 2])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Y_train.values.reshape(-1)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
